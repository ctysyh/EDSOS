## 关于 DPU Net 的补充总结

- DPU Net是一个介于经典局域网和机内设备总线的互联结构：
  - 分布式原生
  - 对于很多传输是Lossy
  - **各个节点平等**
  - 点对点但存在中转的拓扑
  - 带有**时钟同步、时序一致**的要求
  - 传输的数据预声明、配额化、结构已知
  - 延迟量级（私有DDR-DPU硬件）理想平均约150ns、最坏约500ns端到端（邻近机柜PM的src_ddr到dst_ddr）

- DPU内需要提供多种硬件功能：
  - PCAU和路径缓存
  - 本机地址查找表`{TSID, GVA} → GPA`和`{PMID, TSID, LVA} → {TSID, GVA}`
  - 本机内Per-TS的In-flight TID Window及其信用配额
  - 局部视角路由表（在系统初始化的时候建立，可破坏性重加载）
  - （建议性）各个端口独立、并行的基本处理逻辑电路，尤其是每个输入端到每个输出端buffer的直连快速路径

- 路径缓存的具体字段设计：
  - `timetamp`：最近一次命中的时间戳，由硬件自动更新
  - `ident_token`：本节点的身份标识，包括`owner`、`mid`、`refer`
  - `owner_direc_ports_bm`：owner方向的端口位图（应该只有一位置位）
  - `refer_direc_ports_bm`：refer方向的端口位图（可以有多位置位）
  - `gva_16_to_118`：`GVA[16:118]`，共享部分（512B为最细粒度）
  - 共约24B，依次为2B、1B、4B、4B、13B
  - 如果需要ECC，只对后22B做（放弃timetamp），优先保证硬数据的正确性，并大幅降低ECC的更新频率

- 对于边界情况的处理：
  - 建立路径缓存也是采用正常的请求形式，但是通过特殊的消息头来标识，且payload内包含具体的dst_pm和对应的节点大小以及其他附加信息，从而CPU ASIC尝试为PCAU建立新路径缓存；但这个过程是可失败的，特别是当此时路径缓存已经满的时候；这也意味着路径缓存是相对稳定的，而非需要频繁地驱逐的；同时这意味着**从多个可行路径中选择使用路径**的过程是在路径缓存建立时进行的，*静态*选择当时的最优可行，如果建立之后发现需要调整，则需要走一遍路径缓存的释放和新建过程
  - 对于miss的情况，直接返回错误；src可以在看到这个错误后，**重新尝试建立路径缓存**
  - 对于stall的情况，直接返回忙；src自动退避之后重发
  - 可以考虑为路径缓存设置TTL，但每次被命中时刷新；这个可以优化为每次命中的时候硬件自动更新时间戳，然后定时/资源紧张时检查并申请释放长期未命中的项目，申请应该面向refer（即副本方），请求它确认是否仍然需要这个路径

- Lossless和Lossy的权衡：
  - 有句话叫“刚性兑付必然导致流动性危机”，我认为Lossless也是这样的，所以我的思想是始终不保证Lossless，但是发生Loss的时候src可以及时得知、不会静默错误
  - 例如在前面路径缓存的建立分析中，它是可以拒绝的，这个拒绝性也是一种Lossy，但这个Lossy保证了其他的内容不会莫名其妙由正确变错误；其他传输中的边界情况也都是Lossy但会报错的

- 路径缓存建立之后的路径黑盒：
  - 在建立之后，可能有其他的refer加入、并申请成为了新的owner，而这对于本机的应用是无感的
  - 这也是已经建立好的路径缓存必须严格受到保护的原因，因为这些是唯一的信息用于路由
  - 这里更加值得注意的是，GVA NSME是自引导的，GVA NSM Page本身也是依靠路径缓存来访问的，它的缓存也有可能丢（出错），这并不是一个可靠依据；当然，在驱逐的时候通常不会考虑驱逐GVA NSM Page的路径缓存，但意外是不可预测不可避免的；这里设置fallback，在一个TS（GVA空间是Per-TS的）所在的所有PM，在本地至少保留各个GVA NSM Page本身的PMID，确保有慢速路径仍然能够正确访问

- 直达源头的背压：
  - 因为全部内容都是在EDSOS的框架内，所以这部分互联协议完全可以和进程子系统的调度器联动；发生背压的时候，可以直接传达负责管理相应TS的调度器实例，请求其提前（及时处理消息）/延缓（减少发送消息）这个TS的节点执行
  - 当然，这个背压反馈延迟不小，尤其是这个是属于智能调度附加模块的，因此主要的短期流控是信用配额，调度优化属于长期的系统优化

- 对于DPU硬件的优化指导
  - 输入端口之后可以直接接一段线性/分支执行的快速路径逻辑电路，使得消息不会积压在输入端口处，并且快速筛除非本节点需处理的中继消息
  - DPU ASIC/FPGA本身可以实现一些需要数据汇总、缓存分析的固定操作
  - 更多复杂逻辑提请主机CPU处理，尤其是DDR-DPU方案下，主机CPU访问DPU缓存效率极高

